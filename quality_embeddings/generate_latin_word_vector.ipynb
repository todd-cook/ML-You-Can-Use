{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a Latin WordVector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter suggestions brought to you by:\n",
    " * Word2vec applied to Recommendation: Hyperparameters Matter - https://arxiv.org/pdf/1804.04212\n",
    " * How to Generate a Good Word Embedding? - https://arxiv.org/pdf/1507.05523.pdf\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines/key points as quotes:\n",
    "* for semantic property tasks, larger dimensions will lead to better performance \n",
    "* For most NLP tasks a dimensionality of 50 is typically sufficient.\n",
    "* ... multiple iterations are necessary.  The performance increases by a large margin when weiterate more than once, regardless of the task and the cor-pus. \n",
    "* Early stopping for regularization based on minimizing the validation loss isn't as useful as with other ML tasks; ideally a specific test would be implemented, but this is difficult to implement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging \n",
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from cltk.stop.latin import PERSEUS_STOPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG = logging.getLogger('make_word_vec')\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_characteristics = 'non_lemmatized'  \n",
    "# corpus_filename =  'latin_library.preprocessed.cor' \n",
    "\n",
    "# corpus_characteristics = 'lemmatized'  \n",
    "# corpus_filename ='latin_library.lemmatized.preprocessed.cor'\n",
    "\n",
    "corpus_characteristics = ''  \n",
    "corpus_filename ='latin_library.preprocessed.cor'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(PERSEUS_STOPS)\n",
    "# additional stops\n",
    "additional_stops  ='ille iste ispe haec quem illic qui sic hic haec quae '.split()\n",
    "\n",
    "for stop in additional_stops:\n",
    "    STOPWORDS.add(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_wo_stopwords = 'latin_library.wostops.cor'\n",
    "with open(corpus_filename, 'rt') as infile:\n",
    "    with open(corpus_file_wo_stopwords, 'wt') as outfile:\n",
    "        for line in infile:\n",
    "            words = [word for word in line.split() if word not in STOPWORDS]\n",
    "            sent = ' '.join(words).strip()\n",
    "            outfile.write('{}\\n'.format(sent))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : Creating vector with parameters: {\"size\": 50, \"iter\": 30, \"min_count\": 3, \"max_vocab_size\": null, \"ns_exponent\": 0.75, \"alpha\": 0.025, \"min_alpha\": 0.004, \"sg\": 1, \"window\": 10, \"workers\": 7, \"negative\": 15, \"sample\": 0}\n",
      "WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO : collecting all words and their counts\n",
      "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO : PROGRESS: at sentence #10000, processed 132618 words, keeping 23063 word types\n",
      "INFO : PROGRESS: at sentence #20000, processed 252256 words, keeping 34768 word types\n",
      "INFO : PROGRESS: at sentence #30000, processed 402348 words, keeping 44505 word types\n",
      "INFO : PROGRESS: at sentence #40000, processed 547836 words, keeping 53444 word types\n",
      "INFO : PROGRESS: at sentence #50000, processed 703812 words, keeping 60619 word types\n",
      "INFO : PROGRESS: at sentence #60000, processed 845552 words, keeping 66467 word types\n",
      "INFO : PROGRESS: at sentence #70000, processed 982392 words, keeping 75397 word types\n",
      "INFO : PROGRESS: at sentence #80000, processed 1110676 words, keeping 86636 word types\n",
      "INFO : PROGRESS: at sentence #90000, processed 1282325 words, keeping 97778 word types\n",
      "INFO : PROGRESS: at sentence #100000, processed 1364730 words, keeping 99118 word types\n",
      "INFO : PROGRESS: at sentence #110000, processed 1470104 words, keeping 103099 word types\n",
      "INFO : PROGRESS: at sentence #120000, processed 1597626 words, keeping 109128 word types\n",
      "INFO : PROGRESS: at sentence #130000, processed 1722130 words, keeping 114834 word types\n",
      "INFO : PROGRESS: at sentence #140000, processed 1856651 words, keeping 117674 word types\n",
      "INFO : PROGRESS: at sentence #150000, processed 1973992 words, keeping 119702 word types\n",
      "INFO : PROGRESS: at sentence #160000, processed 2088522 words, keeping 121324 word types\n",
      "INFO : PROGRESS: at sentence #170000, processed 2203729 words, keeping 122760 word types\n",
      "INFO : PROGRESS: at sentence #180000, processed 2323037 words, keeping 123762 word types\n",
      "INFO : PROGRESS: at sentence #190000, processed 2431896 words, keeping 124522 word types\n",
      "INFO : PROGRESS: at sentence #200000, processed 2536901 words, keeping 125828 word types\n",
      "INFO : PROGRESS: at sentence #210000, processed 2677292 words, keeping 130617 word types\n",
      "INFO : PROGRESS: at sentence #220000, processed 2795414 words, keeping 134098 word types\n",
      "INFO : PROGRESS: at sentence #230000, processed 2918930 words, keeping 136254 word types\n",
      "INFO : PROGRESS: at sentence #240000, processed 3084348 words, keeping 139690 word types\n",
      "INFO : PROGRESS: at sentence #250000, processed 3249919 words, keeping 145675 word types\n",
      "INFO : PROGRESS: at sentence #260000, processed 3351218 words, keeping 149063 word types\n",
      "INFO : PROGRESS: at sentence #270000, processed 3458284 words, keeping 153313 word types\n",
      "INFO : PROGRESS: at sentence #280000, processed 3570496 words, keeping 155879 word types\n",
      "INFO : PROGRESS: at sentence #290000, processed 3681966 words, keeping 157825 word types\n",
      "INFO : PROGRESS: at sentence #300000, processed 3782500 words, keeping 159940 word types\n",
      "INFO : PROGRESS: at sentence #310000, processed 3880810 words, keeping 161955 word types\n",
      "INFO : PROGRESS: at sentence #320000, processed 3957957 words, keeping 163260 word types\n",
      "INFO : PROGRESS: at sentence #330000, processed 4088662 words, keeping 165827 word types\n",
      "INFO : PROGRESS: at sentence #340000, processed 4217916 words, keeping 168431 word types\n",
      "INFO : PROGRESS: at sentence #350000, processed 4367110 words, keeping 172591 word types\n",
      "INFO : PROGRESS: at sentence #360000, processed 4510380 words, keeping 176429 word types\n",
      "INFO : PROGRESS: at sentence #370000, processed 4661388 words, keeping 179463 word types\n",
      "INFO : PROGRESS: at sentence #380000, processed 4794306 words, keeping 181483 word types\n",
      "INFO : PROGRESS: at sentence #390000, processed 4951639 words, keeping 184093 word types\n",
      "INFO : PROGRESS: at sentence #400000, processed 5040590 words, keeping 185229 word types\n",
      "INFO : PROGRESS: at sentence #410000, processed 5191465 words, keeping 187047 word types\n",
      "INFO : PROGRESS: at sentence #420000, processed 5640455 words, keeping 194137 word types\n",
      "INFO : PROGRESS: at sentence #430000, processed 5765524 words, keeping 196521 word types\n",
      "INFO : PROGRESS: at sentence #440000, processed 5874331 words, keeping 199179 word types\n",
      "INFO : PROGRESS: at sentence #450000, processed 5957620 words, keeping 201053 word types\n",
      "INFO : PROGRESS: at sentence #460000, processed 6056486 words, keeping 202358 word types\n",
      "INFO : PROGRESS: at sentence #470000, processed 6174486 words, keeping 204864 word types\n",
      "INFO : PROGRESS: at sentence #480000, processed 6293839 words, keeping 207156 word types\n",
      "INFO : PROGRESS: at sentence #490000, processed 6427290 words, keeping 210205 word types\n",
      "INFO : PROGRESS: at sentence #500000, processed 6555422 words, keeping 213471 word types\n",
      "INFO : PROGRESS: at sentence #510000, processed 6697183 words, keeping 215960 word types\n",
      "INFO : PROGRESS: at sentence #520000, processed 6761541 words, keeping 217929 word types\n",
      "INFO : PROGRESS: at sentence #530000, processed 6823158 words, keeping 219600 word types\n",
      "INFO : PROGRESS: at sentence #540000, processed 6915120 words, keeping 221158 word types\n",
      "INFO : PROGRESS: at sentence #550000, processed 7077795 words, keeping 222600 word types\n",
      "INFO : PROGRESS: at sentence #560000, processed 7225918 words, keeping 223708 word types\n",
      "INFO : PROGRESS: at sentence #570000, processed 7354234 words, keeping 224629 word types\n",
      "INFO : PROGRESS: at sentence #580000, processed 7474410 words, keeping 225566 word types\n",
      "INFO : PROGRESS: at sentence #590000, processed 7610289 words, keeping 227637 word types\n",
      "INFO : collected 228782 word types from a corpus of 7654487 raw words and 593237 sentences\n",
      "INFO : Loading a fresh vocabulary\n",
      "INFO : effective_min_count=3 retains 117256 unique words (51% of original 228782, drops 111526)\n",
      "INFO : effective_min_count=3 leaves 7513047 word corpus (98% of original 7654487, drops 141440)\n",
      "INFO : deleting the raw counts dictionary of 228782 items\n",
      "INFO : sample=0 downsamples 0 most-common words\n",
      "INFO : downsampling leaves estimated 7513047 word corpus (100.0% of prior 7513047)\n",
      "INFO : estimated required memory for 117256 words and 50 dimensions: 105530400 bytes\n",
      "INFO : resetting layer weights\n",
      "INFO : training model with 7 workers on 117256 vocabulary and 50 features, using sg=1 hs=0 sample=0 negative=15 window=10\n",
      "INFO : EPOCH 1 - PROGRESS: at 16.77% examples, 28657 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 1 - PROGRESS: at 32.56% examples, 55533 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 1 - PROGRESS: at 61.99% examples, 107934 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 1 - PROGRESS: at 100.79% examples, 179034 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 1 : training on 7707269 raw words (7558795 effective words) took 42.2s, 179027 effective words/s\n",
      "INFO : EPOCH 2 - PROGRESS: at 16.77% examples, 27484 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 2 - PROGRESS: at 32.56% examples, 53343 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 2 - PROGRESS: at 61.99% examples, 103641 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 2 - PROGRESS: at 100.79% examples, 172229 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 2 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172224 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : EPOCH 3 - PROGRESS: at 16.77% examples, 27770 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 3 - PROGRESS: at 32.56% examples, 53950 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : EPOCH 3 - PROGRESS: at 76.26% examples, 131214 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 3 - PROGRESS: at 100.79% examples, 174609 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 3 : training on 7707269 raw words (7558795 effective words) took 43.3s, 174604 effective words/s\n",
      "INFO : EPOCH 4 - PROGRESS: at 16.77% examples, 27763 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 4 - PROGRESS: at 32.56% examples, 53933 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : EPOCH 4 - PROGRESS: at 76.26% examples, 131286 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 4 - PROGRESS: at 100.79% examples, 174678 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 4 : training on 7707269 raw words (7558795 effective words) took 43.3s, 174672 effective words/s\n",
      "INFO : EPOCH 5 - PROGRESS: at 16.77% examples, 27574 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : EPOCH 5 - PROGRESS: at 47.82% examples, 79363 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 5 - PROGRESS: at 89.67% examples, 154439 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 5 - PROGRESS: at 100.79% examples, 173636 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 5 : training on 7707269 raw words (7558795 effective words) took 43.5s, 173631 effective words/s\n",
      "INFO : EPOCH 6 - PROGRESS: at 16.77% examples, 27457 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 6 - PROGRESS: at 32.56% examples, 53528 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 6 - PROGRESS: at 61.99% examples, 104428 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 6 - PROGRESS: at 100.79% examples, 172336 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 6 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172331 effective words/s\n",
      "INFO : EPOCH 7 - PROGRESS: at 16.77% examples, 27446 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 7 - PROGRESS: at 32.56% examples, 53161 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 7 - PROGRESS: at 61.99% examples, 103621 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 7 - PROGRESS: at 100.79% examples, 171981 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 7 : training on 7707269 raw words (7558795 effective words) took 44.0s, 171975 effective words/s\n",
      "INFO : EPOCH 8 - PROGRESS: at 16.77% examples, 27380 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : EPOCH 8 - PROGRESS: at 47.82% examples, 78849 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 8 - PROGRESS: at 89.67% examples, 153085 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 8 - PROGRESS: at 100.79% examples, 172012 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 8 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172006 effective words/s\n",
      "INFO : EPOCH 9 - PROGRESS: at 16.77% examples, 27378 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : EPOCH 9 - PROGRESS: at 47.82% examples, 78968 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 9 - PROGRESS: at 89.67% examples, 153366 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 9 - PROGRESS: at 100.79% examples, 172709 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 9 : training on 7707269 raw words (7558795 effective words) took 43.8s, 172704 effective words/s\n",
      "INFO : EPOCH 10 - PROGRESS: at 16.77% examples, 27474 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 10 - PROGRESS: at 32.56% examples, 53300 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 10 - PROGRESS: at 61.99% examples, 103973 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 10 - PROGRESS: at 100.79% examples, 172591 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 10 : training on 7707269 raw words (7558795 effective words) took 43.8s, 172586 effective words/s\n",
      "INFO : EPOCH 11 - PROGRESS: at 16.77% examples, 27495 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 11 - PROGRESS: at 32.56% examples, 53512 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 11 - PROGRESS: at 61.99% examples, 104244 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 11 - PROGRESS: at 100.79% examples, 172730 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 11 : training on 7707269 raw words (7558795 effective words) took 43.8s, 172724 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : EPOCH 12 - PROGRESS: at 16.77% examples, 27394 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 12 - PROGRESS: at 32.56% examples, 53321 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 12 - PROGRESS: at 61.99% examples, 104057 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 12 - PROGRESS: at 100.79% examples, 171997 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 12 : training on 7707269 raw words (7558795 effective words) took 43.9s, 171992 effective words/s\n",
      "INFO : EPOCH 13 - PROGRESS: at 16.77% examples, 27344 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : EPOCH 13 - PROGRESS: at 47.82% examples, 78976 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 13 - PROGRESS: at 89.67% examples, 152971 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 13 - PROGRESS: at 100.79% examples, 172130 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 13 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172125 effective words/s\n",
      "INFO : EPOCH 14 - PROGRESS: at 16.77% examples, 27494 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 14 - PROGRESS: at 32.56% examples, 53160 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 14 - PROGRESS: at 61.99% examples, 103615 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 14 - PROGRESS: at 100.79% examples, 171577 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 14 : training on 7707269 raw words (7558795 effective words) took 44.1s, 171571 effective words/s\n",
      "INFO : EPOCH 15 - PROGRESS: at 16.77% examples, 27383 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 15 - PROGRESS: at 32.56% examples, 53111 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 15 - PROGRESS: at 89.67% examples, 152089 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 15 - PROGRESS: at 100.79% examples, 172316 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 15 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172310 effective words/s\n",
      "INFO : EPOCH 16 - PROGRESS: at 16.77% examples, 27395 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 16 - PROGRESS: at 32.56% examples, 53315 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 16 - PROGRESS: at 62.08% examples, 103826 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 16 - PROGRESS: at 100.79% examples, 171930 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 16 : training on 7707269 raw words (7558795 effective words) took 44.0s, 171925 effective words/s\n",
      "INFO : EPOCH 17 - PROGRESS: at 16.77% examples, 27153 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : EPOCH 17 - PROGRESS: at 47.82% examples, 78365 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 17 - PROGRESS: at 89.67% examples, 151878 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 17 - PROGRESS: at 100.79% examples, 171292 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 17 : training on 7707269 raw words (7558795 effective words) took 44.1s, 171287 effective words/s\n",
      "INFO : EPOCH 18 - PROGRESS: at 16.77% examples, 27520 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 18 - PROGRESS: at 32.56% examples, 53005 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 18 - PROGRESS: at 89.67% examples, 153451 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 18 - PROGRESS: at 100.79% examples, 172228 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 18 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172223 effective words/s\n",
      "INFO : EPOCH 19 - PROGRESS: at 16.77% examples, 27415 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 19 - PROGRESS: at 32.56% examples, 53116 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : EPOCH 19 - PROGRESS: at 76.26% examples, 129134 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 19 - PROGRESS: at 100.79% examples, 171487 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 19 : training on 7707269 raw words (7558795 effective words) took 44.1s, 171482 effective words/s\n",
      "INFO : EPOCH 20 - PROGRESS: at 16.77% examples, 27328 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 20 - PROGRESS: at 32.56% examples, 53241 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 20 - PROGRESS: at 61.99% examples, 103946 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 20 - PROGRESS: at 100.79% examples, 172039 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : EPOCH - 20 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172033 effective words/s\n",
      "INFO : EPOCH 21 - PROGRESS: at 16.77% examples, 27410 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 21 - PROGRESS: at 32.56% examples, 53162 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : EPOCH 21 - PROGRESS: at 76.26% examples, 128988 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 21 - PROGRESS: at 100.79% examples, 172135 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 21 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172130 effective words/s\n",
      "INFO : EPOCH 22 - PROGRESS: at 16.77% examples, 27409 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 22 - PROGRESS: at 32.56% examples, 53331 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 22 - PROGRESS: at 61.99% examples, 103897 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 22 - PROGRESS: at 100.79% examples, 172193 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 22 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172188 effective words/s\n",
      "INFO : EPOCH 23 - PROGRESS: at 16.77% examples, 27517 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 23 - PROGRESS: at 32.56% examples, 53066 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 23 - PROGRESS: at 61.99% examples, 103406 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 23 - PROGRESS: at 100.79% examples, 171672 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 23 : training on 7707269 raw words (7558795 effective words) took 44.0s, 171667 effective words/s\n",
      "INFO : EPOCH 24 - PROGRESS: at 16.77% examples, 27421 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 24 - PROGRESS: at 32.56% examples, 53397 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : EPOCH 24 - PROGRESS: at 61.99% examples, 104171 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 24 - PROGRESS: at 100.79% examples, 172244 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 24 : training on 7707269 raw words (7558795 effective words) took 43.9s, 172239 effective words/s\n",
      "INFO : EPOCH 25 - PROGRESS: at 16.77% examples, 27323 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : EPOCH 25 - PROGRESS: at 47.82% examples, 78506 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 25 - PROGRESS: at 89.67% examples, 152542 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 25 - PROGRESS: at 100.79% examples, 172402 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 25 : training on 7707269 raw words (7558795 effective words) took 43.8s, 172397 effective words/s\n",
      "INFO : EPOCH 26 - PROGRESS: at 16.77% examples, 27186 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : EPOCH 26 - PROGRESS: at 47.82% examples, 78434 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 26 - PROGRESS: at 89.67% examples, 152040 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 26 - PROGRESS: at 100.79% examples, 171487 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 26 : training on 7707269 raw words (7558795 effective words) took 44.1s, 171481 effective words/s\n",
      "INFO : EPOCH 27 - PROGRESS: at 16.77% examples, 27340 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 27 - PROGRESS: at 32.56% examples, 52994 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : EPOCH 27 - PROGRESS: at 76.26% examples, 129126 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 27 - PROGRESS: at 100.79% examples, 171643 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 27 : training on 7707269 raw words (7558795 effective words) took 44.0s, 171637 effective words/s\n",
      "INFO : EPOCH 28 - PROGRESS: at 16.77% examples, 27228 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : EPOCH 28 - PROGRESS: at 47.82% examples, 78528 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : EPOCH 28 - PROGRESS: at 89.67% examples, 152439 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 28 - PROGRESS: at 100.79% examples, 171332 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 28 : training on 7707269 raw words (7558795 effective words) took 44.1s, 171326 effective words/s\n",
      "INFO : EPOCH 29 - PROGRESS: at 16.77% examples, 27518 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 29 - PROGRESS: at 32.56% examples, 53205 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : EPOCH 29 - PROGRESS: at 76.26% examples, 129160 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 29 - PROGRESS: at 100.79% examples, 171370 words/s, in_qsize -1, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 29 : training on 7707269 raw words (7558795 effective words) took 44.1s, 171364 effective words/s\n",
      "INFO : EPOCH 30 - PROGRESS: at 16.77% examples, 27470 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "INFO : EPOCH 30 - PROGRESS: at 32.56% examples, 53124 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "INFO : EPOCH 30 - PROGRESS: at 76.26% examples, 129015 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "INFO : EPOCH 30 - PROGRESS: at 100.79% examples, 171938 words/s, in_qsize -1, out_qsize 1\n",
      "INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "INFO : EPOCH - 30 : training on 7707269 raw words (7558795 effective words) took 44.0s, 171933 effective words/s\n",
      "INFO : training on a 231218070 raw words (226763850 effective words) took 1319.8s, 171821 effective words/s\n"
     ]
    }
   ],
   "source": [
    "keyword_params = {\n",
    "    'size': 50,\n",
    "    'iter': 30,\n",
    "    'min_count': 3, # Ignores all words with total frequency lower than this.\n",
    "    'max_vocab_size': None,\n",
    "    'ns_exponent': 0.75, # the default, optimal for linguistic tasks; also try -0.5 for recommenders\n",
    "    'alpha':  0.025,\n",
    "    'min_alpha': 0.004,\n",
    "    'sg': 1, # skip gram\n",
    "    'window': 10, # number of surrounding words to consider\n",
    "    'workers': multiprocessing.cpu_count() - 1,\n",
    "    'negative': 15, # 15 may be best\n",
    "    'sample': 0 #   0.00001  # sample=1e-05 downsamples 4158 most-common words\n",
    "    #     sample=0.001 downsamples 32 most-common words\n",
    "}\n",
    "LOG.info('Creating vector with parameters: %s', json.dumps(keyword_params))\n",
    "latin_lib_vec = Word2Vec(corpus_file=corpus_file_wo_stopwords, **keyword_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : Saving word2vec for latin library corpus\n",
      "INFO : saving Word2Vec object under latin_library.2019.06.01.vec, separately None\n",
      "INFO : not storing attribute vectors_norm\n",
      "INFO : not storing attribute cum_table\n",
      "INFO : saved latin_library.2019.06.01.vec\n"
     ]
    }
   ],
   "source": [
    "LOG.info('Saving word2vec for latin library corpus')\n",
    "latin_lib_vec.save('latin_library.{}.vec'.format( datetime.now().strftime('%Y.%m.%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('latin_library.vec.{}.params'.format(corpus_characteristics, datetime.now().strftime('%Y.%m.%d')), 'wt') as writer:\n",
    "    json.dump(keyword_params, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the word vectors to disk\n",
    "they should be cross platform, cross language loadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : saving Word2VecKeyedVectors object under latin_library.2019.06.01.kv, separately None\n",
      "INFO : not storing attribute vectors_norm\n",
      "INFO : saved latin_library.2019.06.01.kv\n"
     ]
    }
   ],
   "source": [
    "word_vectors = latin_lib_vec.wv\n",
    "the_filename = 'latin_library.{}.kv'.format(datetime.now().strftime('%Y.%m.%d'))\n",
    "# word_vectors.save_word2vec_format(the_filename, binary=False)\n",
    "word_vectors.save(the_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('uirgo', 0.8270761966705322),\n",
       " ('puellae', 0.8253666162490845),\n",
       " ('coniuge', 0.8226670622825623),\n",
       " ('pudica', 0.8078868389129639),\n",
       " ('toro', 0.797211766242981),\n",
       " ('uxor', 0.7896655797958374),\n",
       " ('inuita', 0.7836523652076721),\n",
       " ('mulier', 0.78020840883255),\n",
       " ('formosa', 0.7798080444335938),\n",
       " ('nupta', 0.7792884111404419)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('puella')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/todd/PycharmProjects/ML-You-Can-Use/p37/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "if 'haec' in latin_lib_vec:\n",
    "    latin_lib_vec.wv.similar_by_word('haec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('interemptis', 0.7972910404205322),\n",
       " ('obsessam', 0.7874257564544678),\n",
       " ('regionem', 0.7604485154151917),\n",
       " ('compellens', 0.7579995393753052),\n",
       " ('obsidione', 0.7536187171936035),\n",
       " ('urbem', 0.7497695088386536),\n",
       " ('populaturi', 0.7447846531867981),\n",
       " ('ciuibus', 0.7440009117126465),\n",
       " ('irruentes', 0.7433646321296692),\n",
       " ('nemine', 0.7394951581954956)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.similar_by_word('uiolenter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : loading Word2VecKeyedVectors object from latin_library.2019.06.01.kv\n",
      "INFO : setting ignored attribute vectors_norm to None\n",
      "INFO : loaded latin_library.2019.06.01.kv\n"
     ]
    }
   ],
   "source": [
    "the_filename = 'latin_library.{}.kv'.format( datetime.now().strftime('%Y.%m.%d'))\n",
    "latin_word_vectors = KeyedVectors.load(the_filename, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('homo', 0.8561000227928162),\n",
       " ('ait', 0.7978405356407166),\n",
       " ('ecce', 0.7895816564559937),\n",
       " ('filius', 0.7844275236129761),\n",
       " ('itaque', 0.784336268901825),\n",
       " ('princeps', 0.7794846296310425),\n",
       " ('egressus', 0.7729367613792419),\n",
       " ('eo', 0.7721001505851746),\n",
       " ('ei', 0.7715548872947693),\n",
       " ('cuius', 0.770010232925415)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_word_vectors.most_similar('uir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uir', 0.8561000227928162),\n",
       " ('mundus', 0.8154703378677368),\n",
       " ('factus', 0.8133982419967651),\n",
       " ('iustus', 0.8085343241691589),\n",
       " ('peccator', 0.8056743144989014),\n",
       " ('tuus', 0.7843465805053711),\n",
       " ('numquid', 0.7827498912811279),\n",
       " ('nemo', 0.7798494100570679),\n",
       " ('stultus', 0.7725919485092163),\n",
       " ('hominis', 0.7723689079284668)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('homo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('liticines', 0.7464401721954346),\n",
       " ('tuba', 0.7431555390357971),\n",
       " ('tubicines', 0.7368534803390503),\n",
       " ('tibicines', 0.7339298129081726),\n",
       " ('intermitterent', 0.7267663478851318),\n",
       " ('cohortaretur', 0.7150977253913879),\n",
       " ('contionantem', 0.7062110304832458),\n",
       " ('tibiis', 0.694241464138031),\n",
       " ('fidibus', 0.6819440722465515),\n",
       " ('tripudiis', 0.6780459880828857)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('canere', topn=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nauita', 0.792907178401947),\n",
       " ('saeuus', 0.7922354340553284),\n",
       " ('lentus', 0.7881541848182678),\n",
       " ('durus', 0.7816176414489746),\n",
       " ('celer', 0.7715222239494324),\n",
       " ('patiens', 0.7708593606948853),\n",
       " ('rusticus', 0.76863032579422),\n",
       " ('subiectat', 0.7670884728431702),\n",
       " ('uelox', 0.7548305988311768),\n",
       " ('terit', 0.7522436380386353)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('piger', topn=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('descendere', 0.7483309507369995),\n",
       " ('conscendere', 0.7236344218254089),\n",
       " ('ire', 0.7135241627693176),\n",
       " ('ascendere', 0.7120531797409058),\n",
       " ('glomerare', 0.7041159868240356),\n",
       " ('tendere', 0.7014951109886169),\n",
       " ('insilit', 0.7014558911323547),\n",
       " ('subsidere', 0.69866544008255),\n",
       " ('attollere', 0.6982595920562744),\n",
       " ('subducere', 0.6909117698669434)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('scandere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('despectare', 0.7084847688674927),\n",
       " ('fatentes', 0.699190080165863),\n",
       " ('uisere', 0.6510680913925171),\n",
       " ('sternentem', 0.6478651762008667),\n",
       " ('properabam', 0.6439028382301331),\n",
       " ('tenderemus', 0.6410418152809143),\n",
       " ('seren', 0.6398051977157593),\n",
       " ('petrum', 0.6358171105384827),\n",
       " ('adstare', 0.6350216865539551),\n",
       " ('sagaci', 0.633321225643158)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.most_similar('praelucere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('frugalior', 0.736150324344635),\n",
       " ('necabatur', 0.7324003577232361),\n",
       " ('consularis', 0.7273312211036682),\n",
       " ('priuatus', 0.7270860075950623),\n",
       " ('clarissimus', 0.7148644924163818),\n",
       " ('optimus', 0.7088893055915833),\n",
       " ('improbissimos', 0.7083759307861328),\n",
       " ('senator', 0.7047805786132812),\n",
       " ('integerrimus', 0.7040387988090515),\n",
       " ('romanus', 0.7024648189544678)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_lib_vec.wv.similar_by_word('ciuis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : loading Word2VecKeyedVectors object from latin_library.2019.03.07.kv\n",
      "INFO : setting ignored attribute vectors_norm to None\n",
      "INFO : loaded latin_library.2019.03.07.kv\n"
     ]
    }
   ],
   "source": [
    "the_lemmatized_filename = 'latin_library.2019.03.07.kv' \n",
    "lem_lat_wordvec = KeyedVectors.load(the_lemmatized_filename, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('puer', 0.5749707818031311),\n",
       " ('iuuenis', 0.5151010751724243),\n",
       " ('uirgo', 0.49944934248924255),\n",
       " ('soror', 0.4523782730102539),\n",
       " ('mater', 0.45129919052124023),\n",
       " ('amare', 0.4469846189022064),\n",
       " ('uxor', 0.44040897488594055),\n",
       " ('maritus', 0.43844184279441833),\n",
       " ('at', 0.4366375207901001),\n",
       " ('coniunx', 0.4324739873409271)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_lat_wordvec.most_similar('puella')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mater', 0.6095702052116394),\n",
       " ('iuuenis', 0.5838768482208252),\n",
       " ('puella', 0.5749707818031311),\n",
       " ('ille', 0.5479326248168945),\n",
       " ('ludere', 0.535244345664978),\n",
       " ('senex', 0.519166111946106),\n",
       " ('uirgo', 0.5188031196594238),\n",
       " ('at', 0.5050873756408691),\n",
       " ('ferre', 0.504031240940094),\n",
       " ('parare', 0.5006879568099976)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_lat_wordvec.most_similar('puer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'eccum' in lem_lat_wordvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eccam', 0.525143027305603),\n",
       " ('attat', 0.49384814500808716),\n",
       " ('popli', 0.44641977548599243),\n",
       " ('scibo', 0.414834201335907),\n",
       " ('surrupta', 0.41333162784576416),\n",
       " ('sycophantiam', 0.3958692252635956),\n",
       " ('quoia', 0.39479494094848633),\n",
       " ('uidulo', 0.39022475481033325),\n",
       " ('optume', 0.38850533962249756),\n",
       " ('erus', 0.38483574986457825)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_lat_wordvec.most_similar('eccum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : loading Word2VecKeyedVectors object from latin_library.2019.03.08.kv\n",
      "INFO : loading vectors from latin_library.2019.03.08.kv.vectors.npy with mmap=r\n",
      "INFO : setting ignored attribute vectors_norm to None\n",
      "INFO : loaded latin_library.2019.03.08.kv\n"
     ]
    }
   ],
   "source": [
    " \n",
    "the_date ='2019.03.08'\n",
    "#the_date =datetime.now().strftime('%Y.%m.%d')\n",
    "the_filename = 'latin_library.{}.kv'.format(the_date )\n",
    "latin_word_vectors = KeyedVectors.load(the_filename, mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : storing 147262x600 projection weights into latin_library.2019.03.08.txt\n"
     ]
    }
   ],
   "source": [
    "the_filename = 'latin_library.{}.txt'.format(the_date)\n",
    "latin_word_vectors.save_word2vec_format(the_filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
